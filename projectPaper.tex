\documentclass[11pt, oneside]{article}   	
\usepackage{geometry}                		
\geometry{letterpaper, margin=1.25in}                   		
\usepackage[parfill]{parskip}    		
\usepackage{graphicx}						
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
%\pagenumbering{gobble}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{wrapfig}
\usepackage{multicol}

\usepackage{listings} %For including R code in LaTex
\lstset{language=R,
    basicstyle=\small\ttfamily,
    stringstyle=\color{DarkGreen},
    otherkeywords={0,1,2,3,4,5,6,7,8,9},
    morekeywords={TRUE,FALSE},
    deletekeywords={data,frame,length,as,character},
    keywordstyle=\color{blue},
    commentstyle=\color{DarkGreen},
} %color Scheme for R code in LaTex

%\begin{bmatrix}
%\bigg|_{}^{}        for "evaluated at..."
%\sim		   for tilde



\title{Group Project:\\
\emph{Evaluation of Statistical Model Accuracy}
}
\author{\hspace{0.0cm}\parbox[t][2.5cm][t]{4cm}{
	Bryce Robinette\\
	David Koster\\
}
\parbox[t][2.5cm][t]{4cm}{
	Jacelyn Villalobos\\
	Jacob Ruiz\\
	%Kursten Reznik\\
}
Kursten Reznik 
}
\date{10/17/2020}							

\begin{document}
\maketitle

\pagebreak

\tableofcontents

\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\break
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}
In this paper, we compare the performance of four statistical models using randomly generated data with normal distribution $N(\mu, \sigma^2)$: The models we are investigating are: K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and the Logistic Regression model (GLM in \textbf\textsf{R}). That is, we analyze these models' accuracy with respect to sample size, number of input variables, the variance of the data, and data scaling.\\
\\
We have been given four precise scenarios for which these models are to be tested. We present them here:\\


\hspace{1.5cm}\parbox[t][2.5cm][t]{8cm}{
	\textbf{Scenario 1}\\
	$\cdot$Sample Size $N = 50.$\\
	$\cdot$Number of Inputs $p = 2$.\\
	$\cdot$No scaling or normalizing the data.
}
\parbox[t][2.5cm][t]{8cm}{
	\textbf{Scenario 2}\\
	$\cdot$Sample Size $N = 500.$\\
	$\cdot$Number of Inputs $p = 2$.\\
	$\cdot$Normalized Data.
}

\hspace{1.5cm}\parbox[t][2.5cm][t]{8cm}{
	\textbf{Scenario 3}\\
	$\cdot$Sample Size $N = 100.$\\
	$\cdot$Number of Inputs $p = 20$.\\
	$\cdot$No scaling or normalizing the data.
}
\parbox[t][2.5cm][t]{8cm}{
	\textbf{Scenario 4}\\
	$\cdot$Sample Size $N = 500.$\\
	$\cdot$Number of Inputs $p = 20$.\\
	$\cdot$Normalized Data.
}

In each of these scenarios, we will investigate the average accuracy of each model as it relates to the variance of the data. It should also be noted that this paper assumes that the reader is familiar with these statistical models and the programming language \textbf\textsf{R}.

\pagebreak


%\begin{mdframed}[backgroundcolor=lightgray]
%\begin{lstlisting}[language=R]
%data.generate = function(mu1, mu2, s, n, p){
%  y = as.factor(c(rep(1,n), rep(2,n)))
%  M = matrix(NA, nrow = 2*n, ncol = p, byrow = 1)
%  df = data.frame(y)
%  for (i in c(1:p)){
%    M[,i] = c(rnorm(n,mu1,s), rnorm(n,mu2,s))
%  }
%  df = cbind(y,M)
%  df = data.frame(df)
%  return(df)
%}
%\end{lstlisting}
%\end{mdframed}


\section{Materials and Methods}
To begin, we perform each model with the parameters outlined in the four given scenarios. These four scenarios will give us our blueprint for analysis. Indeed, for each scenario, we run each model against a number of data sets of identical properties but with increasing variance in our randomly generated data. Each of these data sets are also sampled many times in order to return each model's average accuracy for that data's given variance.\\
Moreover, we then evaluate the accuracy of each model as a function of the variance of the data sets in each scenario and plot the results. This methodology should yield the generalized accuracy of the models given the variance of the data. It should be noted that for this report, we choose our variance $s$ such that $0.1\leq s\leq 2$.\\

%\textcolor{blue}{Furthermore, we compare the accuracy of the models to gain insight into which model should likely be used given a set of data of normal distribution.}
 

\subsection{Data Generation} 
% Discussion on how we generated our data.
We generate our data such that the response variable $y$ has two classes. That is, $y=1$, or $y=2$ with class means $\mu_1=1$ and $\mu_2=0$, respectively. Then we randomly generate values with distribution $N(\mu, \sigma^2)$ for our predictors.\\
\\
It should also be noted that when we have a smaller amount of observations $N$, there is a chance that when sampling the data into testing and training data that we could end up with an imbalanced sample of our response value. To mitigate this, we could sample an approximately equal amount of data with each value of $y$; however, since we are running a multitude of simulations on the data, we can rely on the central limit theorem to obtain our average accuracy.\\ 


%\begin{mdframed}[backgroundcolor=lightgray]
%\begin{lstlisting}[language=R]
%data.generate = function(mu1, mu2, s, n, p){
 % y = as.factor(c(rep(1,n), rep(2,n)))
  %M = matrix(NA, nrow = 2*n, ncol = p, byrow = 1)
  %df = data.frame(y)
  %for (i in c(1:p)){
   % M[,i] = c(rnorm(n,mu1,s), rnorm(n,mu2,s))
  %}
  %df = cbind(y,M)
  %df = data.frame(df)
  %return(df)
%}
%\end{lstlisting}
%\end{mdframed}
\subsection{Choosing our best $k$ for KNN}
In this section we present our best $k$. The very best $k$. In fact, it is the best $k$ in the history of $k$'s. So good it will blow your mind. Here is how we did it....\\
\\
We simulated our KNN model over a thousand generated data sets with differing variances and chose the most common ``best $k$'' that was associated with the data sets. We took this common $k$ to be our generalized $k$-value for our following analysis. We found that the best value of $k$ for our generated data sets was $k = 3$. We keep this value constant throughout the different scenarios.\\
\\
%\textcolor{blue}{Do we want a KNN best $k$ plot? I dunno... maybe?? It would look good but I dont have too much invested in having it.}

\pagebreak
\section{Scenario Analysis}
\subsection{Scenario 1}

\begin{wrapfigure}[]{R}{0.5\textwidth}
\vspace{-0.55cm}
\includegraphics[scale=0.4]{Scenario1v2.png}
\vspace{-.55cm}
\end{wrapfigure}
In this scenario, we compare our models with $N=50$ observations, $p=2$ parameters, and without scaling the data.\\
\\
From the resulting figure, we can conclude that all models diminish in accuracy as the variance increases. This is to be expected given that our data was generated randomly without any underlying function dictating the data generating process. Indeed, LDA and Logistic Regression assume a linear relationship between the response variable and the predictors, while KNN does not make any assumptions about the underlying data. QDA is a decent compromise between KNN and any linear model as it assumes a nonlinear relationship between the predictors and the response.\\
\\
As is evident from the resulting plot, the KNN model performs the best. This is to be expected due to the fact that we have chosen a relatively small $k$ for our analysis which makes our particular KNN model more flexible than it would be with a larger $k$-value. Furthermore, KNN performs best with smaller data sets, which is what we have here. In this regard, we might expect our KNN model to perform better under the assumed circumstances for \emph{Scenario 1}.\\
\\

\subsection{Scenario 2}
\begin{wrapfigure}[]{L}{0.5\textwidth}
\vspace{-0.55cm}
\includegraphics[scale=0.4]{Scenario2v2.png}
\vspace{-.25cm}
\end{wrapfigure}
For scenario 2, we take $N=500$, parameters $p=2$, and we scale the data.\\
\\
We immediately see that the KNN model performs the best. Indeed, as a general rule, when we are presented with a large number of observations and the value of our predictors is small, we want to choose a more flexible model. Due to the large sample size, we are less likely to over-fit, even with a more flexible model. Since we have chosen a relatively low value for $k$, our KNN model has the greatest flexibility and hence, the greatest accuracy over the different variances.\\
\\
We must note that all of the models performed with greater accuracy when the data was scaled. Scaling the data is going to reduce the overall variance in the data. If we have a data set with wide variation, scaling can become a necessary step in order to preserve the accuracy of statistical models. So in this particular scenario, all of our models seem to be doing well; however, the flexible nature of the KNN model makes it a superior predictor in this case.
%By scaling the features to the same range, the algorithm would be sensitive to all of them and not biased to the features with the greater magnitude.\\
%\\
%The LDA, QDA, and Logistic Regression models all perform at approximately the same level of accuracy throughout the data variances. (\emph{like the Backstreet boys $\rightarrow$ TELL ME WHY???})\\

%The other three models are less flexible than the KNN. This includes QDA. QDA allows for more flexibility but it requires more parameters to estimate the accuracy.\\



%\textcolor{blue}{ If you have many classes and not so many sample points, this can be a problem for the QDA model.}\\


%\textcolor{red}{IDENTICAL Y-AXES/VERTICAL SCALING}



\subsection{Scenario 3} %We are allowed to make data at least 100.

Now we take $N=100$, and increase our predictors to $p=20$. The data is not to be scaled in this evaluation.\\
Note that we take a larger value for $N$ than the other scenarios since each level, or predictor, needs some amount of observations. If there are not enough observations in a group, then QDA in \textbf\textsf{R} will throw an error.\\
\begin{wrapfigure}[]{L}{0.6\textwidth}
\vspace{-0.55cm}
\includegraphics[scale=0.4]{Scenario3N=100v3.png}
\vspace{-0.5cm}
\end{wrapfigure}

From the resulting plot, we immediately conclude that increasing our predictors $p$ has yielded higher model accuracy over larger variance of the data in comparison to the results from \emph{Scenario 1}.\\
Since we have defined the number of predictors to be $p=20$, it may result that LDA and QDA perform better since we have increased our parameters. 
That is, QDA  (in general) needs a larger amount of predictors, however since we are not allowing the models the convenience of \emph{``best predictors}'', if the predictors have little significance, then they will not significantly contribute to the overall model accuracy and may lead to an over-fit and little change in predictive accuracy.\\
\\
It could be concluded in cases where data variance is high, LDA and QDA may perform better with a larger number of predictors. However, we should be weary of increasing the number of predictors too high such that we start over-fitting and incorporating too much noise in our models. Furthermore, KNN now performs similar to the other models. KNN begins to struggle when the number of inputs is large.

%Even though more predictors will make QDA a better model in this situation, we see that it still does not out preform the other models.


\pagebreak

\subsection{Scenario 4}
\begin{wrapfigure}[]{R}{0.45\textwidth}
\vspace{-0.55cm}
\includegraphics[scale=0.4]{Scenario4v2.png}
\vspace{-0.75cm}
\end{wrapfigure}
We now increase our number of observations to $N=500$, keep our parameters $p=20$, and scale our data.\\
\\
As we expected from the increased number of input variables, KNN does not outperform any of the other models. The larger number of input variables will help LDA, QDA, and Logistic Regression due to their parametric nature, but diminishes the average accuracy the KNN since it may incorporate ``neighbors'' that have no relationship to the desired response. Indeed, KNNâ€™s accuracy reduced significantly because KNN struggles when there is a large data set and a large amount of predictors. Now, when the data is scaled, the KNN will increase in accuracy but still does not outperform the other models.\\
\\
As in \emph{Scenario 3}, we need to be aware of the possibility of over-fitting due to larger number of predictors. However, since we know the details of our data and the generating process, we need to worry about this less than we would when dealing with other data sets of a more natural origin.\\
\\







\section{Conclusion}

Overall, as the variance in our data increases, the average accuracy decreases throughout all of the different models. This is to be expected given the effect variance has on model accuracy.\\
\\
It seems to be apparent that when given a smaller amount of observations and predictors, our $k$-nearest neighbors is likely to perform the best under these circumstances. Indeed, we may conclude that given a smaller number of predictors, we may rely on the KNN model to perform with highest accuracy under our given circumstances. The following graph yields some insight in to this statement.\\
\\
\begin{center}
\graphicspath{ {MyFRICKINJam.png} }
\includegraphics[scale=0.4]{MyFRICKINJam.png}
\end{center}

The graph that is displayed above is the result of \emph{Scenario 2} but without scaling the data. It is presented to show that even without scaling our data, a smaller number of predictors still allows KNN to outperform the other parametric models.\\

This follows from what we may assume about the other models being of a parametric nature. Since LDA, QDA, and Logistic Regression are all parametric, we should see their average accuracy increase when introduced with more parameters. Of course, as was stated in some of the previous sections, when we start introducing more parameters, we should always be aware of the possibility of over-fitting our models. Again, however in the particular case of this report, we know the nature of our data and the generating process. Hence we worry less about over-fitting or including too much noise in our data.\\
\\
This goes further as we look at the scenarios that have a larger number of observations and predictors. Without being weary of over-fitting, we see that the average accuracy of the parametric models performing better while our non-parametric KNN becomes less accurate as it struggles with large amounts of observations and predictors.\\
\\
We must also author a note about the values we chose for our variance, $s$. There may be more insight to glean if we increase the range of variance in the data. However, in the purview of this report, we conclude that for smaller data sets and a lower number of predictors, we rely on the KNN model to outperform the others. While we see an almost identical degradation in accuracy in all four models when our data set is larger with a larger number of predictors, in reality we may see that the parametric models will perform better as long as the increased number of parameters has statistical significance to the response.\\
\\
Without further speculation, and given the restrictions of this report, we are confident in the conclusion thus far; however, we can not confidently conclude a \emph{best model} in a generalized sense. In spite of a non-conclusory ``best model'', it is hoped that the information yielded by this report further informs us on the nature of these statistical models, allowing us to be more discerning in our future endeavors when presented with real-world data.  



%If we look at scenario 3 and 4 we can see that the higher number of predictors with a low variance have a high accuracy rate


%\vspace{3.0cm}
%\subsection*{Extensions?}
%Instead of normally distributed data, we could assess performance or accuracy of the models over other distribution sets, such as a uniform distribution.
 
%\pagebreak


%\section*{References}





\end{document}